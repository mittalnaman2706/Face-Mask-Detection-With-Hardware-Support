{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images with Mask:  1915\n",
      "Number of Images without Mask:  1975\n"
     ]
    }
   ],
   "source": [
    "# About the Dataset\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"Number of Images with Mask: \",len(os.listdir(r'C:\\Users\\user\\Desktop\\Face-Mask-Detection-Using-Hardware\\dataset\\with_mask')))\n",
    "print(\"Number of Images without Mask: \",len(os.listdir(r'C:\\Users\\user\\Desktop\\Face-Mask-Detection-Using-Hardware\\dataset\\without_mask')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Images present our dataset!\n",
      "C:\\Users\\user\\Desktop\\Face-Mask-Detection-Using-Hardware\\dataset\\with_mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\PIL\\Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\Face-Mask-Detection-Using-Hardware\\dataset\\without_mask\n",
      "Data Preprocessing Completed!\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "DATASET_DIRECTORY = r\"C:\\Users\\user\\Desktop\\Face-Mask-Detection-Using-Hardware\\dataset\"\n",
    "TYPES = [\"with_mask\", \"without_mask\"]\n",
    "\n",
    "# All the Images Array will be appended in data list, whereas, the label of images(with_mask or without_mask) will be appended in labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "print(\"Loading Images present our dataset!\")\n",
    "\n",
    "for dir_type in TYPES:\n",
    "    path = os.path.join(DATASET_DIRECTORY,dir_type)\n",
    "    print(path);\n",
    "    #listdir(path) function will list down all the diretories in the path specified\n",
    "    for img in os.listdir(path):\n",
    "        image_path = os.path.join(path,img)\n",
    "        \n",
    "        #Loading Image and setting it's target size to 224x224\n",
    "        image = load_img(image_path, target_size=(224,224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        \n",
    "        data.append(image)\n",
    "        labels.append(dir_type)\n",
    "\n",
    "# We've got the data as numerical values, however, the labels are still alphabetical values\n",
    "# Thus we will convert them into categorical variables using LabelBinarizer from sklearn library\n",
    "\n",
    "#This is performing BINARY ENCODING on labels\n",
    "binarizer = LabelBinarizer()\n",
    "labels = binarizer.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype = \"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Data Preprocessing Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split into Training and Testing Data!\n"
     ]
    }
   ],
   "source": [
    "#Splitting data into Training and Testing Data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size = 0.15, stratify = labels, random_state = 42)\n",
    "\n",
    "print(\"Data Split into Training and Testing Data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Augmentation Completed!\n"
     ]
    }
   ],
   "source": [
    "#Data Augmentation: Constructing the Training Image Generator\n",
    "#This kind of creates many images from a single image by changing some of their properties\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "aug = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.15, shear_range=0.15,\n",
    "horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "print(\"Data Augmentation Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Base Model Completed!\n"
     ]
    }
   ],
   "source": [
    "#Loading MobileNetV2 to create a base model for better results\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "print(\"Base Model Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head Model Created!\n",
      "Final Model Ready for training!\n"
     ]
    }
   ],
   "source": [
    "# We will construct the headModel that will be placed on top of the baseModel !! (THIS WILL BECOME THE MODEL THAT WE WILL TRAIN)\n",
    "\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "print(\"Head Model Created!\")\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "print(\"Final Model Ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Compilation started!\n",
      "Model Compilation completed!\n",
      "Head Training started!\n",
      "Epoch 1/20\n",
      "103/103 [==============================] - 75s 733ms/step - loss: 0.3867 - accuracy: 0.8320 - val_loss: 0.1119 - val_accuracy: 0.9726\n",
      "Epoch 2/20\n",
      "103/103 [==============================] - 79s 772ms/step - loss: 0.1447 - accuracy: 0.9478 - val_loss: 0.0667 - val_accuracy: 0.9863\n",
      "Epoch 3/20\n",
      "103/103 [==============================] - 97s 942ms/step - loss: 0.0964 - accuracy: 0.9633 - val_loss: 0.0503 - val_accuracy: 0.9863\n",
      "Epoch 4/20\n",
      "103/103 [==============================] - 118s 1s/step - loss: 0.0861 - accuracy: 0.9701 - val_loss: 0.0434 - val_accuracy: 0.9897\n",
      "Epoch 5/20\n",
      "103/103 [==============================] - 119s 1s/step - loss: 0.0679 - accuracy: 0.9771 - val_loss: 0.0391 - val_accuracy: 0.9897\n",
      "Epoch 6/20\n",
      "103/103 [==============================] - 120s 1s/step - loss: 0.0645 - accuracy: 0.9762 - val_loss: 0.0376 - val_accuracy: 0.9897\n",
      "Epoch 7/20\n",
      "103/103 [==============================] - 117s 1s/step - loss: 0.0485 - accuracy: 0.9823 - val_loss: 0.0342 - val_accuracy: 0.9932\n",
      "Epoch 8/20\n",
      "103/103 [==============================] - 117s 1s/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.0327 - val_accuracy: 0.9932\n",
      "Epoch 9/20\n",
      "103/103 [==============================] - 85s 826ms/step - loss: 0.0426 - accuracy: 0.9850 - val_loss: 0.0316 - val_accuracy: 0.9932\n",
      "Epoch 10/20\n",
      "103/103 [==============================] - 80s 780ms/step - loss: 0.0364 - accuracy: 0.9869 - val_loss: 0.0315 - val_accuracy: 0.9932\n",
      "Epoch 11/20\n",
      "103/103 [==============================] - 83s 806ms/step - loss: 0.0375 - accuracy: 0.9881 - val_loss: 0.0343 - val_accuracy: 0.9932\n",
      "Epoch 12/20\n",
      " 71/103 [===================>..........] - ETA: 22s - loss: 0.0329 - accuracy: 0.9889"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Initializing Learning Rate, Number of Epochs to train for, Batch Size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "# Freeze all the layers of baseModel which will not update during the first training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compiling the model\n",
    "print(\"Model Compilation started!\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "print(\"Model Compilation completed!\")\n",
    "\n",
    "# Train the head of the network\n",
    "print(\"Head Training started!\")\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=BS), steps_per_epoch=len(trainX) // BS, validation_data=(testX, testY), \n",
    "              validation_steps=len(testX) // BS, epochs=EPOCHS)\n",
    "print(\"Head Training completed!\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "print(\"Network Evaluation!\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "print(\"Classification Report after testing!\")\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs, target_names=binarizer.classes_))\n",
    "\n",
    "print(\"Saving the model named mask_detector.model to disc\")\n",
    "model.save(\"mask_detector.model\", save_format=\"h5\")\n",
    "\n",
    "# Epoch VS Accuracy Curve\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "print(\"Saving EPOCH vs Accuracy Plot to disc!\")\n",
    "plt.savefig(\"epoch_vs_accuracy_plot.png\")\n",
    "\n",
    "print(\"Model Created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
